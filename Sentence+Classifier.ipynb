{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "# Sentence Classification "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "# Pre-Processing Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "import nltk, re, pprint\n",
    "import pandas as pd\n",
    "import re\n",
    "from nltk import word_tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single Text File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['### abstract ###',\n",
       " 'Fitness functions based on test cases are very common in Genetic Programming (GP)',\n",
       " 'This process can be assimilated to a learning task, with the inference of models from a limited number of samples',\n",
       " 'This paper is an investigation on two methods to improve generalization in GP-based learning: 1) the selection of the best-of-run individuals using a three data sets methodology, and 2) the application of parsimony pressure in order to reduce the complexity of the solutions',\n",
       " 'Results using GP in a binary classification setup show that while the accuracy on the test sets is preserved, with less variances compared to baseline results, the mean tree size obtained with the tested methods is significantly reduced']"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Unlabled text file\n",
    "unlab_file = open(\"unlabeled.txt\", \"r\")\n",
    "unlab_text = unlab_file.read()\n",
    "unlab_list = unlab_text.split('\\n')\n",
    "\n",
    "# List of sentences\n",
    "unlab_list[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'### abstract ###\\nMISC Although the Internet AS-level topology has been extensively studied over the past few years, little is known about the details of the AS taxonomy\\nMISC An AS \"node\" can represent a wide variety of organizations, e g , large ISP, or small private business, university, with vastly different network characteristics, external connectivity patterns, network growth tendencies, and other properties that we can hardly neglect while working on veracious Internet representations in simulation environments\\nAIMX In this paper, we introduce a radically new approach based on machine learning techniques to map all the ASes in the Internet into a natural AS taxonomy\\nOWNX We successfully classify ~95.3\\\\% of ASes with expected accuracy of ~78.1\\\\%\\nOWNX We release to the community the AS-level topology dataset augmented with: 1) the AS taxonomy information and 2) the set of AS attributes we used to classify ASes\\nOWNX We believe that this dataset will serve as an invaluable addition to further understanding of the structure and evolution of the Internet\\n### introduction ###\\nMISC The rapid expansion of the Internet in the last two decades has produced a large-scale system of thousands of diverse, independently managed networks that collectively provide global connectivity across a wide spectrum of geopolitical environments\\nMISC From 1997 to 2005 the number of globally routable AS identifiers has increased from less than 2,000 to more than 20,000, exerting significant pressure on interdomain routing as well as other functional and structural parts of the Internet\\nMISC This impressive growth has resulted in a heterogenous and highly complex system that challenges accurate and realistic modeling of the Internet infrastructure\\nMISC In particular, the AS-level topology is an intermix of networks owned and operated by many different organizations, e g , backbone providers, regional providers, access providers, universities and private companies\\nMISC Statistical information that faithfully characterizes different AS types is on the critical path toward understanding the structure of the Internet, as well as for modeling its topology and growth\\nMISC In topology modeling, knowledge of AS types is mandatory for augmenting synthetically constructed or measured AS topologies with realistic intra-AS and inter-AS router-level topologies\\nMISC For example, we expect the network of a dual-homed university to be drastically different from that of a dual-homed small company\\nMISC The university will likely contain dozens of internal routers, thousands of hosts, and many other network elements (switches, servers, firewalls)\\nMISC On the other hand, the small company will most probably have a single router and a simple network topology\\nMISC Since there is such a diversity among different network types, we cannot accurately augment the AS-level topology with appropriate router-level topologies if we cannot characterize the composing ASes\\nMISC Moreover, annotating the ASes in the AS topology with their types is a prerequisite for modeling the evolution of the Internet, since different types of ASes exhibit different growth patterns\\nMISC For example, Internet Service Providers (ISP) grow by attracting new customers and by engaging in business agreements with other ISPs\\nMISC On the other hand, small companies that connect to the Internet through one or few ISPs do not grow significantly over time\\nMISC Thus, categorizing different types of ASes in the Internet is necessary to identify network evolution patterns and develop accurate evolution models\\nMISC An AS taxonomy is also necessary for mapping IP addresses to different types of users\\nMISC For example, in traffic analysis studies its often required to distinguish between packets that come from home and business users\\nMISC Given an AS taxonomy, its possible to realize this goal by checking the type of AS that originates the prefix in which an IP address lies\\nAIMX In this work, we introduce a radically new approach based on machine learning to construct a representative AS taxonomy\\nOWNX We develop an algorithm to classify ASes based on empirically observed differences between AS characteristics\\nBASE We use a large set of data from the Internet Routing Registries~(IRR)~ CITATION  and from RouteViews~ CITATION  to identify intrinsic differences between ASes of different types\\nOWNX Then, we employ a novel machine learning technique to build a classification algorithm that exploits these differences to classify ASes into six representative classes that reflect ASes with different network properties and infrastructures\\nOWNX We derive macroscopic statistics on the different types of ASes in the Internet and validate our results using a sample of~1200 manually identified AS types\\nOWNX Our validation demonstrates that our classification algorithm achieves high accuracy:~78 1\\\\% of the examined classifications were correct\\nOWNX Finally, we make our results and our classifier publicly available to promote further research and understanding of the Internet\\'s structure and evolution\\nOWNX In Section~ we start with a brief discussion of related work\\nOWNX Section~ describes the data we used, and in Section~ we specify the set of AS classes we use in our experiments\\nOWNX Section~ introduces our classification approach and results\\nOWNX We validate them in Section~ and conclude in Section~\\n'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Labeled text file\n",
    "text_file = open(\"arxiv_annotate1_13_3.txt\", \"r\")\n",
    "text_file = text_file.read()\n",
    "text_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'Label': 'MISC', 'Sentence': '# # # abstract # # #'},\n",
       " {'Label': 'MISC',\n",
       "  'Sentence': 'Although the Internet AS-level topology has been extensively studied over the past few years , little is known about the details of the AS taxonomy'},\n",
       " {'Label': 'AIMX',\n",
       "  'Sentence': \"An AS `` node '' can represent a wide variety of organizations , e g , large ISP , or small private business , university , with vastly different network characteristics , external connectivity patterns , network growth tendencies , and other properties that we can hardly neglect while working on veracious Internet representations in simulation environments\"},\n",
       " {'Label': 'OWNX',\n",
       "  'Sentence': 'In this paper , we introduce a radically new approach based on machine learning techniques to map all the ASes in the Internet into a natural AS taxonomy'},\n",
       " {'Label': 'OWNX',\n",
       "  'Sentence': 'We successfully classify ~95.3\\\\ % of ASes with expected accuracy of ~78.1\\\\ %'}]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "############ Word Tokenization ############\n",
    "\n",
    "# Tokenizes the text file\n",
    "text_list = nltk.word_tokenize(text_file)\n",
    "\n",
    "############ Sentence Segmentation ############\n",
    "sents_list = []   # List of sentences from text \n",
    "temp_list = []    # Stores words temporary to form sentences\n",
    "\n",
    "# Iterates through the list of words to extract sents\n",
    "for word in text_list:\n",
    "    # If the current word is a label do the following\n",
    "    if re.fullmatch(r'[A-Z]{4}', word):\n",
    "        # Dictionary for each sentence\n",
    "        sents_temp = {}\n",
    "        sents_temp[\"Sentence\"] = \" \".join(temp_list)\n",
    "        sents_temp[\"Label\"] = word\n",
    "        sents_list.append(sents_temp)\n",
    "        \n",
    "        # Reset the list & increment count\n",
    "        temp_list = [] \n",
    "    else:\n",
    "        temp_list.append(word)\n",
    "\n",
    "# List of dictionaries where each entry represents a sentence & its label\n",
    "sents_list[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arxiv_annotate1_13_3.txt: 34 sentences\n"
     ]
    }
   ],
   "source": [
    "# Number of sentences\n",
    "print(\"{}: {} sentences\".format(\"arxiv_annotate1_13_3.txt\", len(sents_list)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiple Text Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['arxiv_annotate10_7_3.txt',\n",
       " 'arxiv_annotate1_13_3.txt',\n",
       " 'arxiv_annotate2_66_3.txt',\n",
       " 'arxiv_annotate3_80_3.txt',\n",
       " 'arxiv_annotate4_168_3.txt',\n",
       " 'arxiv_annotate5_240_3.txt',\n",
       " 'arxiv_annotate6_52_3.txt',\n",
       " 'arxiv_annotate7_268_3.txt',\n",
       " 'arxiv_annotate8_81_3.txt',\n",
       " 'arxiv_annotate9_279_3.txt',\n",
       " 'jdm_annotate10_210_3.txt',\n",
       " 'jdm_annotate1_103_3.txt',\n",
       " 'jdm_annotate2_107_3.txt',\n",
       " 'jdm_annotate3_120_3.txt',\n",
       " 'jdm_annotate4_220_3.txt',\n",
       " 'jdm_annotate5_228_3.txt',\n",
       " 'jdm_annotate6_32_3.txt',\n",
       " 'jdm_annotate7_265_3.txt',\n",
       " 'jdm_annotate8_177_3.txt',\n",
       " 'jdm_annotate9_45_3.txt',\n",
       " 'plos_annotate10_1140_3.txt',\n",
       " 'plos_annotate1_6_3.txt',\n",
       " 'plos_annotate2_336_3.txt',\n",
       " 'plos_annotate3_798_3.txt',\n",
       " 'plos_annotate4_1052_3.txt',\n",
       " 'plos_annotate5_1375_3.txt',\n",
       " 'plos_annotate6_1032_3.txt',\n",
       " 'plos_annotate7_1233_3.txt',\n",
       " 'plos_annotate8_123_3.txt',\n",
       " 'plos_annotate9_1187_3.txt']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "root = \"C:/Users/Leo Pascual/Desktop/UCSD/Fall_Quarter_2017/Cogs_109/Final_Project/SentenceCorpus/labeled_articles\"\n",
    "textfiles = []\n",
    "\n",
    "# Directory that contains all the text files\n",
    "directory = os.listdir(root)\n",
    "\n",
    "for file in directory:\n",
    "    if file.endswith(\"3.txt\"):\n",
    "        textfiles.append(file)\n",
    "\n",
    "# 30 annotated text files\n",
    "textfiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'Label': 'OWNX', 'Sentence': '# # # abstract # # #'},\n",
       " {'Label': 'MISC',\n",
       "  'Sentence': 'The Minimum Description Length principle for online sequence estimation/prediction in a proper learning setup is studied'},\n",
       " {'Label': 'MISC',\n",
       "  'Sentence': 'If the underlying model class is discrete , then the total expected square loss is a particularly interesting performance measure : ( a ) this quantity is finitely bounded , implying convergence with probability one , and ( b ) it additionally specifies the convergence speed'},\n",
       " {'Label': 'AIMX',\n",
       "  'Sentence': 'For MDL , in general one can only have loss bounds which are finite but exponentially larger than those for Bayes mixtures'},\n",
       " {'Label': 'OWNX',\n",
       "  'Sentence': 'We show that this is even the case if the model class contains only Bernoulli distributions'}]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "textwrappers = []       # Stores all textwrappers before being read\n",
    "textfile_tokens = []    # Stores each textfiles list of words\n",
    "\n",
    "# Opens all the files\n",
    "for file in textfiles:\n",
    "    textwrappers.append(open(file, 'r'))\n",
    "    \n",
    "############ Word Tokenization ############\n",
    "# Tokenizes each file \n",
    "for text in textwrappers:\n",
    "    temp_list = []\n",
    "    body_text = text.read()\n",
    "    temp_list = nltk.word_tokenize(body_text)\n",
    "    textfile_tokens.append(temp_list)\n",
    "\n",
    "    \n",
    "################ Sentence Segmentation ################\n",
    "sents_list = []   # List of sentences from text \n",
    "temp_list = []    # Stores words temporary to form sentences\n",
    "\n",
    "# Iterates through each list of tokens \n",
    "for text_list in textfile_tokens:\n",
    "    # Iterates through the list of words to extract sents\n",
    "    for word in text_list:\n",
    "        # If the current word: is a label do the following\n",
    "        if re.fullmatch(r'(AIMX|OWNX|CONT|BASE|MISC)', word):\n",
    "            # Dictionary for each sentence\n",
    "            sents_temp = {}\n",
    "            sents_temp[\"Sentence\"] = \" \".join(temp_list)\n",
    "            sents_temp[\"Label\"] = word\n",
    "            sents_list.append(sents_temp)\n",
    "\n",
    "            # Reset the list \n",
    "            temp_list = [] \n",
    "        else:\n",
    "            # Forms the sentence until a label is found\n",
    "            temp_list.append(word)\n",
    "\n",
    "# List of sentences and their label\n",
    "sents_list[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1040"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of labled sentences out of the 30 text files\n",
    "len(sents_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td># # # abstract # # #</td>\n",
       "      <td>OWNX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Minimum Description Length principle for o...</td>\n",
       "      <td>MISC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>If the underlying model class is discrete , th...</td>\n",
       "      <td>MISC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>For MDL , in general one can only have loss bo...</td>\n",
       "      <td>AIMX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>We show that this is even the case if the mode...</td>\n",
       "      <td>OWNX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>We derive a new upper bound on the prediction ...</td>\n",
       "      <td>OWNX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>This implies a small bound ( comparable to the...</td>\n",
       "      <td>OWNX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>We discuss the application to Machine Learning...</td>\n",
       "      <td>MISC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>`` Bayes mixture '' , `` Solomonoff induction ...</td>\n",
       "      <td>MISC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>In many cases however , the Bayes mixture is c...</td>\n",
       "      <td>MISC</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Sentence Label\n",
       "0                               # # # abstract # # #  OWNX\n",
       "1  The Minimum Description Length principle for o...  MISC\n",
       "2  If the underlying model class is discrete , th...  MISC\n",
       "3  For MDL , in general one can only have loss bo...  AIMX\n",
       "4  We show that this is even the case if the mode...  OWNX\n",
       "5  We derive a new upper bound on the prediction ...  OWNX\n",
       "6  This implies a small bound ( comparable to the...  OWNX\n",
       "7  We discuss the application to Machine Learning...  MISC\n",
       "8  `` Bayes mixture '' , `` Solomonoff induction ...  MISC\n",
       "9  In many cases however , the Bayes mixture is c...  MISC"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "########### Transfering sentences into a Data Frame ###########\n",
    "\n",
    "# Training set\n",
    "df = pd.DataFrame.from_dict(sents_list, orient = 'columns')\n",
    "df = df[['Sentence', 'Label']]\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_code_all_hidden": true,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
